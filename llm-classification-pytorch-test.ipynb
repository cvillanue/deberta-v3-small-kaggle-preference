{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":86518,"databundleVersionId":9809560,"sourceType":"competition"},{"sourceId":12548514,"sourceType":"datasetVersion","datasetId":7922869}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"For this competition, I chose to fine-tune DeBERTa-v3-small, a lightweight language model built on the Transformer architecture, using PyTorch and the Hugging Face Transformers library. \n\nDeBERTa-v3-small is a compact version of the DeBERTa family that still delivers impressive results. It‚Äôs designed to understand language deeply, but with fewer parameters, which means faster training and lower memory usage without sacrificing too much accuracy (thank god - because running this on Kaggle can be challenging).\n\nüß© Better Understanding of Language Structure\nThis ‚Äúdisentangled attention‚Äù helps it make more precise comparisons\n\n‚ö° Efficient for Limited Compute\nSince this is a Kaggle competition with time and compute limits, using a smaller model like this meant I could train faster (in under 2 hours!) and iterate more easily - a big win when exploring different strategies and tuning hyperparameters.\n\n\nFeel fee to modify: Callyn V. ","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nfrom datasets import Dataset\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\nfrom sklearn.metrics import accuracy_score\n\ntrain = pd.read_csv('/kaggle/input/llm-classification-finetuning/train.csv')\ntest = pd.read_csv('/kaggle/input/llm-classification-finetuning/test.csv')\nsample_submission = pd.read_csv('/kaggle/input/llm-classification-finetuning/sample_submission.csv')\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-23T21:32:02.430116Z","iopub.execute_input":"2025-07-23T21:32:02.430410Z","iopub.status.idle":"2025-07-23T21:32:34.377680Z","shell.execute_reply.started":"2025-07-23T21:32:02.430380Z","shell.execute_reply":"2025-07-23T21:32:34.376875Z"}},"outputs":[{"name":"stderr","text":"2025-07-23 21:32:18.475859: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1753306338.662183      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1753306338.712797      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Combine labels into one column\ndef get_winner(row):\n    if row['winner_model_a'] == 1:\n        return 'a'\n    elif row['winner_model_b'] == 1:\n        return 'b'\n    else:\n        return 'tie'\n\ntrain['winner'] = train.apply(get_winner, axis=1)\nlabel2id = {'a': 0, 'b': 1, 'tie': 2}\n\n# Split train/valid\ntrain_split = train.sample(frac=0.9, random_state=42)\nvalid_split = train.drop(train_split.index)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T21:32:51.408379Z","iopub.execute_input":"2025-07-23T21:32:51.408813Z","iopub.status.idle":"2025-07-23T21:32:51.784023Z","shell.execute_reply.started":"2025-07-23T21:32:51.408784Z","shell.execute_reply":"2025-07-23T21:32:51.783224Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# No longer downloading from Hugging Face!\ntokenizer = AutoTokenizer.from_pretrained('/kaggle/input/deberta-v3-small-offline/deberta-v3-small')\n\ndef tokenize_function(examples):\n    return tokenizer(\n        [p + ' [SEP] ' + a + ' [SEP] ' + b for p, a, b in zip(examples['prompt'], examples['response_a'], examples['response_b'])],\n        truncation=True,\n        padding='max_length',\n        max_length=512,\n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T21:35:01.970458Z","iopub.execute_input":"2025-07-23T21:35:01.971186Z","iopub.status.idle":"2025-07-23T21:35:02.389267Z","shell.execute_reply.started":"2025-07-23T21:35:01.971161Z","shell.execute_reply":"2025-07-23T21:35:02.388700Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def prepare_dataset(df):\n    hf_dataset = Dataset.from_pandas(df[['prompt', 'response_a', 'response_b', 'winner']])\n    hf_dataset = hf_dataset.map(tokenize_function, batched=True)\n    hf_dataset = hf_dataset.map(lambda x: {'labels': [label2id[w] for w in x['winner']]}, batched=True)\n    hf_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n    return hf_dataset\n\ntrain_ds = prepare_dataset(train_split)\nvalid_ds = prepare_dataset(valid_split)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T21:35:13.297211Z","iopub.execute_input":"2025-07-23T21:35:13.297475Z","iopub.status.idle":"2025-07-23T21:36:21.011959Z","shell.execute_reply.started":"2025-07-23T21:35:13.297456Z","shell.execute_reply":"2025-07-23T21:36:21.011130Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/51729 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1335b9531eb940e8a7e0412ef1915951"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/51729 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c19d9dd5af74d6e8fa518d57a61d048"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5748 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eae9ecfb923747eb936618ae05deb3d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5748 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6b7b20e39964c9b9c41484a2bf83e93"}},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"Model & Trainer","metadata":{}},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\n    '/kaggle/input/deberta-v3-small-offline/deberta-v3-small',\n    num_labels=3\n)\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    preds = np.argmax(logits, axis=-1)\n    return {'accuracy': accuracy_score(labels, preds)}\n\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    eval_strategy='epoch',\n    save_strategy='epoch',\n    num_train_epochs=4,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    learning_rate=2e-5,\n    weight_decay=0.01,\n    load_best_model_at_end=True,\n    logging_dir='./logs',\n    logging_steps=500,\n    logging_first_step=True,\n    fp16=True,         # Helps with DeBERTa on P100 (recommended)\n    report_to=[],      # Turn off WandB/huggingface hub\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_ds,\n    eval_dataset=valid_ds,\n    compute_metrics=compute_metrics,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T21:36:59.854372Z","iopub.execute_input":"2025-07-23T21:36:59.855178Z","iopub.status.idle":"2025-07-23T21:37:05.426245Z","shell.execute_reply.started":"2025-07-23T21:36:59.855147Z","shell.execute_reply":"2025-07-23T21:37:05.425461Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"print(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T21:37:57.566292Z","iopub.execute_input":"2025-07-23T21:37:57.566828Z","iopub.status.idle":"2025-07-23T21:37:57.571446Z","shell.execute_reply.started":"2025-07-23T21:37:57.566803Z","shell.execute_reply":"2025-07-23T21:37:57.570705Z"}},"outputs":[{"name":"stdout","text":"DebertaV2ForSequenceClassification(\n  (deberta): DebertaV2Model(\n    (embeddings): DebertaV2Embeddings(\n      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): DebertaV2Encoder(\n      (layer): ModuleList(\n        (0-5): 6 x DebertaV2Layer(\n          (attention): DebertaV2Attention(\n            (self): DisentangledSelfAttention(\n              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n              (pos_dropout): Dropout(p=0.1, inplace=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): DebertaV2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): DebertaV2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaV2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (rel_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n    )\n  )\n  (pooler): ContextPooler(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (dropout): Dropout(p=0, inplace=False)\n  )\n  (classifier): Linear(in_features=768, out_features=3, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"There are 128,100 tokens in the vocab, each mapped to a 768-dimensional vector.\nEach layer has:\n* DisentangledSelfAttention: A signature DeBERTa improvement over standard self-attention. It separates content-based and position-based attention.\n* A feedforward layer that expands from 768 ‚Üí 3072 dims (GELU activation).\n* output: Projects it back to 768 and normalizes.","metadata":{}},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T21:39:14.189193Z","iopub.execute_input":"2025-07-23T21:39:14.189473Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='24590' max='25868' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [24590/25868 2:17:52 < 07:09, 2.97 it/s, Epoch 3.80/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.085900</td>\n      <td>1.081407</td>\n      <td>0.411795</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.042000</td>\n      <td>1.068620</td>\n      <td>0.424495</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.974400</td>\n      <td>1.100474</td>\n      <td>0.433890</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"test_hf = Dataset.from_pandas(test)\ntest_hf = test_hf.map(tokenize_function, batched=True)\ntest_hf.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n\n# Get Predictions\npredictions = trainer.predict(test_hf)\npreds = np.argmax(predictions.predictions, axis=-1)\n\n# Map numeric labels back to text\nid2label = {0: 'winner_model_a', 1: 'winner_model_b', 2: 'winner_model_tie'}\nsubmission = sample_submission.copy()\nsubmission['winner_model_a'] = (preds == 0).astype(int)\nsubmission['winner_model_b'] = (preds == 1).astype(int)\nsubmission['winner_model_tie'] = (preds == 2).astype(int)\n\n# Drop any extra columns if needed\nsubmission = submission[['id', 'winner_model_a', 'winner_model_b', 'winner_model_tie']]\n\nsubmission.to_csv('submission.csv', index=False)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(submission.head())\nprint(submission.sum())   \n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}